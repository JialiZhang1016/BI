# Thinking1	什么是监督学习，无监督学习，半监督学习
### 监督学习
有特征有标签。训练集数据有标签，用这些数据训练模型，预测没有标签的数据。比如CART决策树。  
### 无监督学习
有特征无标签。通过聚类算法对数据进行打标签。比如K-means, 层次聚类。  
### 半监督学习
有特征部分有标签。利用没有标签的数据来学习整个数据的潜在分布。比如标签传播算法。


# Thinking2	K-means中的k值如何选取
参考https://blog.csdn.net/sxllllwd/article/details/82151996
### 1.手肘法
利用SSE(sum of the squared errors，误差平方和)来判断，SSE下降对快的那个点就是我们想选取的K。
### 2.轮廓系数法
- 计算样本 i 到同簇其他样本的平均距离 a(i)，a(i)称为簇内部相似度；  
- 计算样本 i 到其他簇所有样本的平均距离 b(i),b(i)称为簇间不相似度；  
- 样本 i 的轮廓系数 $$s(i)=(b(i)-a(i))/max{a(i),b(i)}$$  
- s(i)取值在[-1,1]之间，s(i)接近 1，说明样本 i 聚类合理;s(i)接近-1，说明样本 i 应该分类至其他簇。  
- 所有样本的轮廓系数均值称为聚类结果的轮廓系数。  

轮廓系数是评价聚类是否合理有效的指标。需要去给定不同 k 值，根据聚类结果计算轮廓系数，比较判断聚类是否合理，从而决定选择哪一种 K 值的聚类结果。

# Thinking3	随机森林采用了bagging集成学习，bagging指的是什么
1. 从样本集中使用Boostaping（有放回）抽取n个训练样本。共进行K轮抽取，训练出K个模型。
2. 分别使用K个模型做预测，用投票的方式得到最终的分类结果。

# Thinking4	表征学习和半监督学习的区别是什么
### 表征学习
表征学习（Representation Learning），也称为特征学习(feature learning)目的是对复杂的原始数据化繁为简，把原始数据的无效信息剔除，把有效信息更有效地进行提炼，形成特征，如果特征被有效提取， 那么之后的学习任务会更简单和精确。 
### 半监督学习
半监督学习介于监督学习与无监督学习之间通常半监督学习的任务与监督学习一致，即任务中包含有明确的目标（如分类），采用的数据既包括有标签的数据，也包括无标签的数据。作用：只有少量的数据有Label，利用没有标签的数据来学习整个数据的潜在分布。
